{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0a2c913",
   "metadata": {},
   "source": [
    "# Djiba Kaba\n",
    "### Immo Predictor — Valorisation et Diagnostic Intelligent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4626f1",
   "metadata": {},
   "source": [
    "# Objectif :\n",
    "- **Régression** : Estimer le prix d'un bien immobilier (`SalePrice`)\n",
    "- **Classification** : Classifier automatiquement son type (`BldgType`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711f0ffd",
   "metadata": {},
   "source": [
    "## Étapes :\n",
    "1. Analyse Exploratoire des Données (EDA)\n",
    "2. Pré-traitement : gestion des valeurs manquantes, encodage, normalisation\n",
    "3. Modélisation :\n",
    "   - **Régression** : Decision Tree, Random Forest → MAE, RMSE, R²\n",
    "   - **Classification** : SVM, Random Forest → Accuracy, F1-score, Matrice de confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000001",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. Importation des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    accuracy_score, f1_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "sns.set_style('whitegrid')\n",
    "print('Bibliothèques importées avec succès.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000003",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "print(f'Dimensions du dataset : {df.shape}')\n",
    "print(f'Nombre de lignes     : {df.shape[0]}')\n",
    "print(f'Nombre de colonnes   : {df.shape[1]}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000003b",
   "metadata": {},
   "source": [
    "> **Lecture :** Le dataset Ames Housing contient **1 460 observations** et **81 variables** décrivant des biens immobiliers vendus à Ames, Iowa. Chaque ligne représente une maison avec ses caractéristiques physiques, sa localisation, sa qualité et son prix de vente. La richesse des variables (surface, qualité, année, quartier, équipements) offre un cadre idéal pour entraîner des modèles de régression et de classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000005",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Analyse Exploratoire des Données (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000006",
   "metadata": {},
   "source": [
    "### 2.1 Types des colonnes et statistiques descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000007",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== Types de données ===')\n",
    "print(df.dtypes.value_counts())\n",
    "print(f'\\nVariables numériques    : {df.select_dtypes(include=np.number).shape[1]}')\n",
    "print(f'Variables catégorielles : {df.select_dtypes(include=\"object\").shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000008",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000008b",
   "metadata": {},
   "source": [
    "> **Interprétation :** Le dataset est un mélange de **43 variables numériques** et **38 variables catégorielles**. Les statistiques descriptives révèlent des échelles très hétérogènes : `LotArea` peut atteindre 215 245 pieds², tandis que `PoolArea` a une moyenne quasiment nulle. Cette dispersion d'échelles justifie l'application d'une **standardisation** pour le SVM, qui y est sensible. Les percentiles montrent également que de nombreuses variables (comme `PoolArea` ou `3SsnPorch`) ont une médiane à 0, signifiant que la majorité des biens n'ont pas ces équipements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000009",
   "metadata": {},
   "source": [
    "### 2.2 Valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000010",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "missing_pct = (missing / len(df) * 100).round(2)\n",
    "\n",
    "missing_df = pd.DataFrame({'Nb NaN': missing, '% NaN': missing_pct})\n",
    "print(f'Colonnes avec valeurs manquantes : {len(missing)}\\n')\n",
    "print(missing_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000011",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "missing.plot(kind='bar', color='steelblue', edgecolor='white')\n",
    "plt.title('Nombre de valeurs manquantes par colonne', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Colonnes')\n",
    "plt.ylabel('Nombre de NaN')\n",
    "plt.xticks(rotation=45, ha='right', fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000011b",
   "metadata": {},
   "source": [
    "> **Interprétation :** Le dataset compte **19 colonnes** contenant des valeurs manquantes. On distingue deux catégories :\n",
    ">\n",
    "> - **Manquants structurels (>80%)** : `PoolQC`, `MiscFeature`, `Alley`, `Fence` ont plus de 80% de NaN. Ces valeurs manquantes ne sont pas des erreurs — elles signifient simplement que le bien n'a pas la caractéristique (pas de piscine, pas d'accès à une ruelle, etc.). Ces colonnes ne font pas partie de nos features sélectionnées.\n",
    ">\n",
    "> - **Manquants partiels (<20%)** : `GarageType`, `GarageFinish`, `BsmtQual`, `TotalBsmtSF`, `GarageArea`, `GarageCars` ont un faible taux de NaN. Ces colonnes utilisées dans nos modèles seront traitées par **imputation médiane** (variables numériques) et **imputation par la valeur la plus fréquente** (variables catégorielles)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000012",
   "metadata": {},
   "source": [
    "### 2.3 Distribution de la variable cible — SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000013",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(df['SalePrice'], bins=50, color='steelblue', edgecolor='white')\n",
    "axes[0].set_title('Distribution de SalePrice', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Prix de vente ($)')\n",
    "axes[0].set_ylabel('Fréquence')\n",
    "axes[0].axvline(df['SalePrice'].mean(), color='red', linestyle='--', label=f'Moyenne : {df[\"SalePrice\"].mean():,.0f} $')\n",
    "axes[0].axvline(df['SalePrice'].median(), color='orange', linestyle='--', label=f'Médiane : {df[\"SalePrice\"].median():,.0f} $')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].hist(np.log1p(df['SalePrice']), bins=50, color='coral', edgecolor='white')\n",
    "axes[1].set_title('Distribution de log(SalePrice)', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('log(Prix de vente)')\n",
    "axes[1].set_ylabel('Fréquence')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Moyenne   : {df[\"SalePrice\"].mean():,.0f} $')\n",
    "print(f'Médiane   : {df[\"SalePrice\"].median():,.0f} $')\n",
    "print(f'Std       : {df[\"SalePrice\"].std():,.0f} $')\n",
    "print(f'Min / Max : {df[\"SalePrice\"].min():,.0f} $ / {df[\"SalePrice\"].max():,.0f} $')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000013b",
   "metadata": {},
   "source": [
    "> **Interprétation :** La distribution de `SalePrice` est **asymétrique à droite** (*right-skewed*) : la majorité des biens se vendent entre **100 000 $ et 250 000 $**, mais une queue longue vers la droite (quelques biens très chers) tire la moyenne (≈181 000 $) au-dessus de la médiane (≈163 000 $). Cela indique la présence de **valeurs extrêmes** (outliers) dans les prix élevés.\n",
    ">\n",
    "> Après transformation **logarithmique** (`log1p`), la distribution devient quasi-normale, ce qui serait bénéfique pour des modèles linéaires. Nos modèles à base d'arbres (Decision Tree, Random Forest) étant non paramétriques et insensibles à la forme de la distribution, nous conserverons la valeur originale de `SalePrice` comme cible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000014",
   "metadata": {},
   "source": [
    "### 2.4 Corrélations avec SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000015",
   "metadata": {},
   "outputs": [],
   "source": [
    "REG_FEATURES = [\n",
    "    'GrLivArea', 'TotalBsmtSF', 'LotArea', 'BedroomAbvGr', 'FullBath',\n",
    "    'TotRmsAbvGrd', 'OverallQual', 'OverallCond', 'YearBuilt',\n",
    "    'YearRemodAdd', 'GarageCars', 'GarageArea', 'PoolArea', 'Fireplaces'\n",
    "]\n",
    "\n",
    "corr_df = df[REG_FEATURES + ['SalePrice']].corr()\n",
    "\n",
    "plt.figure(figsize=(13, 11))\n",
    "sns.heatmap(\n",
    "    corr_df, annot=True, fmt='.2f', cmap='coolwarm',\n",
    "    center=0, linewidths=0.5, square=True,\n",
    "    annot_kws={'size': 8}\n",
    ")\n",
    "plt.title('Matrice de corrélation — Features de régression', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000015b",
   "metadata": {},
   "source": [
    "> **Interprétation :** La heatmap met en évidence plusieurs relations importantes :\n",
    ">\n",
    "> - **Corrélations fortes avec `SalePrice`** : `OverallQual` (r ≈ 0.79), `GrLivArea` (r ≈ 0.71), `GarageArea` (r ≈ 0.64), `GarageCars` (r ≈ 0.64). Ces variables sont les prédicteurs les plus puissants du prix.\n",
    "> - **Corrélations modérées** : `YearBuilt`, `YearRemodAdd`, `TotalBsmtSF`, `FullBath`, `TotRmsAbvGrd`.\n",
    "> - **Corrélations faibles** : `PoolArea` (r ≈ 0.09), `OverallCond` (r ≈ 0.09), `BedroomAbvGr` (r ≈ 0.17). Contre-intuitivement, le nombre de chambres est peu corrélé avec le prix — une maison peut avoir beaucoup de petites chambres et coûter moins cher.\n",
    "> - **Multicolinéarité** : `GarageArea` et `GarageCars` sont fortement corrélées entre elles (r ≈ 0.88), de même que `YearBuilt` et `YearRemodAdd` (r ≈ 0.59). Cela ne pose pas de problème pour les arbres de décision, mais pourrait affecter des modèles linéaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000016",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_target = corr_df['SalePrice'].drop('SalePrice').sort_values(ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['coral' if v < 0 else 'steelblue' for v in corr_target]\n",
    "corr_target.plot(kind='barh', color=colors, edgecolor='white')\n",
    "plt.axvline(0, color='black', linewidth=0.8)\n",
    "plt.title('Corrélation des features avec SalePrice', fontsize=13, fontweight='bold')\n",
    "plt.xlabel('Coefficient de corrélation de Pearson')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000016b",
   "metadata": {},
   "source": [
    "> **Interprétation :** Ce graphique confirme le classement des features par pertinence pour prédire `SalePrice`. `OverallQual` se détache nettement avec la corrélation la plus élevée (~0.79) : la qualité perçue d'une maison est le facteur le plus déterminant de son prix. Toutes les variables sélectionnées ont une corrélation positive — il n'y a aucune relation inversée significative. `PoolArea` et `BedroomAbvGr` contribuent le moins au modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000017",
   "metadata": {},
   "source": [
    "### 2.5 Nuages de points — Features numériques vs SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000018",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats_plot = ['GrLivArea', 'TotalBsmtSF', 'OverallQual', 'YearBuilt', 'GarageArea', 'LotArea']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "for ax, feat in zip(axes.flatten(), num_feats_plot):\n",
    "    ax.scatter(df[feat], df['SalePrice'], alpha=0.3, color='steelblue', s=15)\n",
    "    ax.set_xlabel(feat)\n",
    "    ax.set_ylabel('SalePrice ($)')\n",
    "    ax.set_title(f'{feat} vs SalePrice')\n",
    "\n",
    "plt.suptitle('Features numériques vs SalePrice', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000018b",
   "metadata": {},
   "source": [
    "> **Interprétation :** Ces scatter plots permettent de visualiser la nature des relations entre les features et le prix :\n",
    ">\n",
    "> - **GrLivArea** : relation quasi-linéaire et positive. Deux outliers en bas à droite (très grande surface, prix anormalement bas) — probablement des ventes atypiques (saisies, enchères).\n",
    "> - **TotalBsmtSF** : tendance positive claire. Les biens sans sous-sol (TotalBsmtSF = 0) forment un groupe à gauche avec des prix variés.\n",
    "> - **OverallQual** : relation la plus nette — chaque palier de qualité (1 à 10) correspond à une plage de prix distinctement plus élevée. La dispersion croît avec la qualité, traduisant une plus grande variabilité pour les biens de luxe.\n",
    "> - **YearBuilt** : les maisons récentes tendent à valoir plus cher, mais la relation est diffuse pour les constructions avant 1950, reflétant la diversité des marchés historiques.\n",
    "> - **GarageArea** : tendance positive, avec un groupe de points à 0 (biens sans garage) qui maintiennent des prix relativement modérés.\n",
    "> - **LotArea** : relation très faible et très dispersée. La superficie du terrain n'est pas un bon prédicteur linéaire du prix — quelques terrains immenses sont vendus à des prix étonnamment bas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000019",
   "metadata": {},
   "source": [
    "### 2.6 Distribution de BldgType (variable cible — Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000020",
   "metadata": {},
   "outputs": [],
   "source": [
    "bldg_counts = df['BldgType'].value_counts()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "bldg_counts.plot(kind='bar', ax=axes[0], color='seagreen', edgecolor='white')\n",
    "axes[0].set_title('Distribution de BldgType', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Type de bâtiment')\n",
    "axes[0].set_ylabel('Nombre')\n",
    "axes[0].tick_params(axis='x', rotation=0)\n",
    "for i, v in enumerate(bldg_counts):\n",
    "    axes[0].text(i, v + 5, str(v), ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "axes[1].pie(bldg_counts, labels=bldg_counts.index, autopct='%1.1f%%',\n",
    "            startangle=90, colors=sns.color_palette('Set2'))\n",
    "axes[1].set_title('Répartition de BldgType (%)', fontsize=13, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(bldg_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000020b",
   "metadata": {},
   "source": [
    "> **Interprétation :** La variable cible `BldgType` est fortement **déséquilibrée** :\n",
    ">\n",
    "> | Type | Signification | Proportion |\n",
    "> |---|---|---|\n",
    "> | `1Fam` | Maison individuelle | ~84% |\n",
    "> | `TwnhsE` | Maison de ville (extrémité) | ~7% |\n",
    "> | `Duplex` | Duplex | ~4% |\n",
    "> | `Twnhs` | Maison de ville (intérieure) | ~3% |\n",
    "> | `2fmCon` | Maison bi-familiale | ~2% |\n",
    ">\n",
    "> Ce fort déséquilibre est un **défi majeur pour la classification** : les modèles auront naturellement tendance à prédire `1Fam` pour maximiser l'accuracy, au détriment des classes minoritaires. C'est pourquoi le **F1-score pondéré** (qui tient compte du déséquilibre) sera plus pertinent que l'accuracy seule pour évaluer les performances réelles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000021",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Pré-traitement\n",
    "### 3.1 Sélection des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000022",
   "metadata": {},
   "outputs": [],
   "source": [
    "REG_FEATURES = [\n",
    "    'GrLivArea', 'TotalBsmtSF', 'LotArea', 'BedroomAbvGr', 'FullBath',\n",
    "    'TotRmsAbvGrd', 'OverallQual', 'OverallCond', 'YearBuilt',\n",
    "    'YearRemodAdd', 'Neighborhood', 'GarageCars', 'GarageArea', 'PoolArea', 'Fireplaces'\n",
    "]\n",
    "TARGET_REG = 'SalePrice'\n",
    "\n",
    "CLF_FEATURES = [\n",
    "    'GrLivArea', 'TotRmsAbvGrd', 'OverallQual', 'YearBuilt',\n",
    "    'GarageCars', 'Neighborhood', 'HouseStyle'\n",
    "]\n",
    "TARGET_CLF = 'BldgType'\n",
    "\n",
    "print('Features régression     :', REG_FEATURES)\n",
    "print('\\nFeatures classification :', CLF_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000023",
   "metadata": {},
   "source": [
    "### 3.2 Pré-traitement pour la Régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000024",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df[REG_FEATURES + [TARGET_REG]].copy()\n",
    "print(f'Dataset régression : {df_reg.shape}')\n",
    "print(f'\\nValeurs manquantes avant traitement :')\n",
    "print(df_reg.isnull().sum()[df_reg.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000025",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_reg = df_reg[REG_FEATURES].select_dtypes(include=np.number).columns.tolist()\n",
    "cat_cols_reg = df_reg[REG_FEATURES].select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Imputation médiane pour les numériques, mode pour les catégorielles\n",
    "num_imputer_reg = SimpleImputer(strategy='median')\n",
    "df_reg[num_cols_reg] = num_imputer_reg.fit_transform(df_reg[num_cols_reg])\n",
    "\n",
    "cat_imputer_reg = SimpleImputer(strategy='most_frequent')\n",
    "df_reg[cat_cols_reg] = cat_imputer_reg.fit_transform(df_reg[cat_cols_reg])\n",
    "\n",
    "# Encodage LabelEncoder pour la variable catégorielle (Neighborhood)\n",
    "le_reg = LabelEncoder()\n",
    "for col in cat_cols_reg:\n",
    "    df_reg[col] = le_reg.fit_transform(df_reg[col])\n",
    "\n",
    "print(f'Valeurs manquantes après traitement : {df_reg.isnull().sum().sum()}')\n",
    "print(f'\\nColonnes numériques     : {num_cols_reg}')\n",
    "print(f'Colonnes catégorielles  : {cat_cols_reg}')\n",
    "df_reg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000025b",
   "metadata": {},
   "source": [
    "> **Interprétation :** Après pré-traitement :\n",
    "> - Les valeurs numériques manquantes (ex. `GarageArea`, `GarageCars`) sont remplacées par la **médiane** de la colonne — choix robuste aux valeurs extrêmes, contrairement à la moyenne.\n",
    "> - La variable catégorielle `Neighborhood` est imputée par la **valeur la plus fréquente**, puis convertie en entier via `LabelEncoder`. Cette approche est adaptée aux arbres de décision qui peuvent capturer des relations ordinales implicites entre les catégories.\n",
    "> - Le dataset régression est maintenant **100% numérique**, sans aucune valeur manquante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000027",
   "metadata": {},
   "source": [
    "### 3.3 Pré-traitement pour la Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000028",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clf = df[CLF_FEATURES + [TARGET_CLF]].copy()\n",
    "\n",
    "num_cols_clf = df_clf[CLF_FEATURES].select_dtypes(include=np.number).columns.tolist()\n",
    "cat_cols_clf = df_clf[CLF_FEATURES].select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Imputation\n",
    "num_imputer_clf = SimpleImputer(strategy='median')\n",
    "df_clf[num_cols_clf] = num_imputer_clf.fit_transform(df_clf[num_cols_clf])\n",
    "\n",
    "cat_imputer_clf = SimpleImputer(strategy='most_frequent')\n",
    "df_clf[cat_cols_clf + [TARGET_CLF]] = cat_imputer_clf.fit_transform(df_clf[cat_cols_clf + [TARGET_CLF]])\n",
    "\n",
    "# Encodage des features catégorielles\n",
    "le_clf = LabelEncoder()\n",
    "for col in cat_cols_clf:\n",
    "    df_clf[col] = le_clf.fit_transform(df_clf[col])\n",
    "\n",
    "# Encodage de la cible\n",
    "le_target = LabelEncoder()\n",
    "df_clf[TARGET_CLF] = le_target.fit_transform(df_clf[TARGET_CLF])\n",
    "\n",
    "print(f'Classes encodées : {dict(enumerate(le_target.classes_))}')\n",
    "print(f'Valeurs manquantes après traitement : {df_clf.isnull().sum().sum()}')\n",
    "df_clf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000029b",
   "metadata": {},
   "source": [
    "> **Interprétation :** Les variables catégorielles `Neighborhood` et `HouseStyle` sont encodées avec `LabelEncoder`. La variable cible `BldgType` est également encodée (0 = 1Fam, 1 = 2fmCon, 2 = Duplex, 3 = Twnhs, 4 = TwnhsE). Une **standardisation** sera appliquée uniquement pour le SVM dans la section suivante, car les SVMs sont sensibles aux différences d'échelles entre features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000030",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Régression — Estimation du Prix (`SalePrice`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000031",
   "metadata": {},
   "source": [
    "### 4.1 Division Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000032",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reg = df_reg[REG_FEATURES]\n",
    "y_reg = df_reg[TARGET_REG]\n",
    "\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f'Taille Train : {X_train_r.shape}  ({len(X_train_r)/len(X_reg)*100:.0f}%)')\n",
    "print(f'Taille Test  : {X_test_r.shape}  ({len(X_test_r)/len(X_reg)*100:.0f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000032b",
   "metadata": {},
   "source": [
    "> **Choix méthodologique :** Le dataset est divisé en **80% d'entraînement** (1168 observations) et **20% de test** (292 observations). Le paramètre `random_state=42` garantit la **reproductibilité** des résultats. Avec 1460 observations, cette répartition offre suffisamment de données pour l'entraînement tout en conservant un ensemble de test représentatif."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000033",
   "metadata": {},
   "source": [
    "### 4.2 Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000034",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_reg = DecisionTreeRegressor(max_depth=10, min_samples_split=5, random_state=42)\n",
    "dt_reg.fit(X_train_r, y_train_r)\n",
    "y_pred_dt_r = dt_reg.predict(X_test_r)\n",
    "\n",
    "mae_dt_r  = mean_absolute_error(y_test_r, y_pred_dt_r)\n",
    "rmse_dt_r = np.sqrt(mean_squared_error(y_test_r, y_pred_dt_r))\n",
    "r2_dt_r   = r2_score(y_test_r, y_pred_dt_r)\n",
    "\n",
    "print('=== Decision Tree Regressor ===')\n",
    "print(f'MAE  : {mae_dt_r:>12,.2f} $')\n",
    "print(f'RMSE : {rmse_dt_r:>12,.2f} $')\n",
    "print(f'R²   : {r2_dt_r:>12.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000034b",
   "metadata": {},
   "source": [
    "> **Interprétation :** Le Decision Tree (`max_depth=10`) livre une première estimation du prix. Le **MAE** indique l'erreur absolue moyenne en dollars — en moyenne, le modèle se trompe de cette somme sur chaque prédiction. Le **RMSE** (plus sensible aux grandes erreurs) est plus élevé, révélant la présence d'outliers de prédiction. Le **R²** mesure la proportion de variance expliquée : une valeur proche de 1 serait idéale. Malgré sa profondeur limitée à 10 niveaux pour réduire le surapprentissage, l'arbre unique reste sensible au bruit des données d'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000035",
   "metadata": {},
   "source": [
    "### 4.3 Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000036",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RandomForestRegressor(\n",
    "    n_estimators=200, max_depth=15,\n",
    "    min_samples_split=5, random_state=42, n_jobs=-1\n",
    ")\n",
    "rf_reg.fit(X_train_r, y_train_r)\n",
    "y_pred_rf_r = rf_reg.predict(X_test_r)\n",
    "\n",
    "mae_rf_r  = mean_absolute_error(y_test_r, y_pred_rf_r)\n",
    "rmse_rf_r = np.sqrt(mean_squared_error(y_test_r, y_pred_rf_r))\n",
    "r2_rf_r   = r2_score(y_test_r, y_pred_rf_r)\n",
    "\n",
    "print('=== Random Forest Regressor ===')\n",
    "print(f'MAE  : {mae_rf_r:>12,.2f} $')\n",
    "print(f'RMSE : {rmse_rf_r:>12,.2f} $')\n",
    "print(f'R²   : {r2_rf_r:>12.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000036b",
   "metadata": {},
   "source": [
    "> **Interprétation :** Le Random Forest (200 arbres) obtient de meilleures performances que le Decision Tree sur les trois métriques. Cette amélioration s'explique par le principe d'**ensemble learning** : chaque arbre est entraîné sur un sous-échantillon aléatoire des données (*bootstrap*) et sur un sous-ensemble aléatoire des features (*feature bagging*). La **moyenne des prédictions** de 200 arbres réduit la variance et lisse les erreurs individuelles. Le R² nettement plus élevé confirme que ce modèle capture mieux les relations complexes et non-linéaires du marché immobilier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000037",
   "metadata": {},
   "source": [
    "### 4.4 Comparaison des modèles de Régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000038",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_reg = pd.DataFrame({\n",
    "    'Modèle':   ['Decision Tree', 'Random Forest'],\n",
    "    'MAE ($)':  [mae_dt_r,  mae_rf_r],\n",
    "    'RMSE ($)': [rmse_dt_r, rmse_rf_r],\n",
    "    'R²':       [r2_dt_r,   r2_rf_r]\n",
    "})\n",
    "print(results_reg.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000039",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "colors = ['steelblue', 'coral']\n",
    "\n",
    "for ax, metric in zip(axes, ['MAE ($)', 'RMSE ($)', 'R²']):\n",
    "    bars = ax.bar(results_reg['Modèle'], results_reg[metric], color=colors, edgecolor='white', width=0.5)\n",
    "    ax.set_title(f'Comparaison — {metric}', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(metric)\n",
    "    for bar, val in zip(bars, results_reg[metric]):\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            bar.get_height() * 1.01,\n",
    "            f'{val:,.0f}' if metric != 'R²' else f'{val:.4f}',\n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold'\n",
    "        )\n",
    "\n",
    "plt.suptitle('Comparaison des modèles de Régression', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000039b",
   "metadata": {},
   "source": [
    "> **Interprétation :** Le **Random Forest domine clairement** sur les trois métriques :\n",
    "> - **MAE plus faible** → l'erreur moyenne absolue est réduite : le modèle est globalement plus précis.\n",
    "> - **RMSE plus faible** → les grandes erreurs de prédiction sont moins fréquentes : le modèle est plus robuste aux cas difficiles.\n",
    "> - **R² plus élevé** → une plus grande part de la variabilité des prix est expliquée par le modèle.\n",
    ">\n",
    "> Le Decision Tree, bien qu'interprétable et rapide, pâtit d'une **variance élevée** : il mémorise trop les données d'entraînement et généralise moins bien sur les nouvelles observations. Le Random Forest, en agrégeant des centaines d'arbres, lisse ces imperfections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000040",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for ax, (y_pred, title) in zip(axes, [\n",
    "    (y_pred_dt_r, 'Decision Tree'),\n",
    "    (y_pred_rf_r, 'Random Forest')\n",
    "]):\n",
    "    ax.scatter(y_test_r, y_pred, alpha=0.4, color='steelblue', s=15)\n",
    "    mn, mx = y_test_r.min(), y_test_r.max()\n",
    "    ax.plot([mn, mx], [mn, mx], 'r--', lw=2, label='Prédiction parfaite')\n",
    "    ax.set_xlabel('Prix réel ($)')\n",
    "    ax.set_ylabel('Prix prédit ($)')\n",
    "    ax.set_title(f'{title} — Réel vs Prédit')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000040b",
   "metadata": {},
   "source": [
    "> **Interprétation :** La diagonale rouge représente la **prédiction parfaite** (prix prédit = prix réel). Plus les points sont proches de cette ligne, meilleur est le modèle.\n",
    ">\n",
    "> - **Decision Tree** : les points sont plus dispersés autour de la diagonale, avec des erreurs importantes notamment pour les prix médians. Le modèle produit des prédictions en « marches d'escalier » typiques des arbres (il ne peut prédire que des valeurs discrètes correspondant aux feuilles).\n",
    "> - **Random Forest** : les points sont nettement mieux alignés sur la diagonale, signe d'une meilleure précision. On observe toutefois une **sous-estimation systématique** pour les biens très chers (> 400 000 $) — les propriétés de luxe sont rares dans le dataset, ce qui rend leur prédiction difficile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000041",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_reg = pd.Series(rf_reg.feature_importances_, index=REG_FEATURES).sort_values(ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "importances_reg.plot(kind='barh', color='steelblue', edgecolor='white')\n",
    "plt.title('Importance des features — Random Forest Régression', fontsize=13, fontweight='bold')\n",
    "plt.xlabel('Importance relative')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000041b",
   "metadata": {},
   "source": [
    "> **Interprétation :** Ce graphique classe les features par leur **contribution moyenne à la réduction de l'impureté** au sein du Random Forest :\n",
    ">\n",
    "> - **OverallQual** : la qualité globale est de loin la variable la plus importante, cohérente avec sa corrélation de 0.79 avec le prix.\n",
    "> - **GrLivArea** (surface habitable) et **GarageArea** / **GarageCars** suivent — les acheteurs valorisent fortement l'espace et le stationnement.\n",
    "> - **YearBuilt** et **Neighborhood** : l'âge du bien et la localisation ont un impact significatif sur le prix.\n",
    "> - **PoolArea** et **BedroomAbvGr** : ces variables contribuent très peu — une piscine ou le nombre de chambres seul n'est pas déterminant pour le prix dans ce marché.\n",
    ">\n",
    "> Ces résultats sont cohérents avec la réalité du marché immobilier : la qualité, la surface et l'emplacement sont les trois piliers du prix d'un bien."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000042",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Classification — Type de Bâtiment (`BldgType`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000043",
   "metadata": {},
   "source": [
    "### 5.1 Division Train / Test + Standardisation (pour SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000044",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clf = df_clf[CLF_FEATURES]\n",
    "y_clf = df_clf[TARGET_CLF]\n",
    "\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X_clf, y_clf, test_size=0.2, random_state=42, stratify=y_clf\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_c)\n",
    "X_test_scaled  = scaler.transform(X_test_c)\n",
    "\n",
    "print(f'Taille Train : {X_train_c.shape}')\n",
    "print(f'Taille Test  : {X_test_c.shape}')\n",
    "print(f'\\nDistribution des classes dans le test :')\n",
    "print(pd.Series(y_test_c).map(dict(enumerate(le_target.classes_))).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000044b",
   "metadata": {},
   "source": [
    "> **Choix méthodologique :** L'option `stratify=y_clf` garantit que la proportion de chaque classe de `BldgType` est **préservée** dans les ensembles train et test — essentiel avec un dataset aussi déséquilibré. La **StandardScaler** est appliquée uniquement aux données destinées au SVM : elle centre et réduit chaque feature (moyenne = 0, écart-type = 1). Le scaler est ajusté (`fit`) uniquement sur les données d'entraînement pour éviter toute fuite d'information (*data leakage*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000045",
   "metadata": {},
   "source": [
    "### 5.2 SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000046",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC(kernel='rbf', C=10, gamma='scale', random_state=42)\n",
    "svm_clf.fit(X_train_scaled, y_train_c)\n",
    "y_pred_svm = svm_clf.predict(X_test_scaled)\n",
    "\n",
    "acc_svm = accuracy_score(y_test_c, y_pred_svm)\n",
    "f1_svm  = f1_score(y_test_c, y_pred_svm, average='weighted')\n",
    "\n",
    "print('=== SVM (kernel=RBF, C=10) ===')\n",
    "print(f'Accuracy : {acc_svm:.4f}')\n",
    "print(f'F1-score : {f1_svm:.4f}')\n",
    "print()\n",
    "print('Rapport de classification :')\n",
    "print(classification_report(y_test_c, y_pred_svm, target_names=le_target.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000046b",
   "metadata": {},
   "source": [
    "> **Interprétation :** Le SVM avec noyau RBF (*Radial Basis Function*) affiche une **accuracy élevée, mais trompeuse**. En raison du déséquilibre des classes, cette métrique est gonflée par la classe dominante `1Fam`. Le rapport de classification révèle le vrai tableau :\n",
    ">\n",
    "> - **`1Fam`** : excellentes précision et rappel — le modèle prédit bien la classe majoritaire.\n",
    "> - **`TwnhsE`, `Duplex`, `Twnhs`, `2fmCon`** : précision et rappel nettement plus faibles — le SVM peine à distinguer ces types rares.\n",
    ">\n",
    "> Le noyau RBF projette les données dans un espace de dimension supérieure pour trouver un hyperplan séparateur optimal, mais le déséquilibre extrême limite ses performances sur les classes minoritaires."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000047",
   "metadata": {},
   "source": [
    "### 5.3 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000048",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=200, max_depth=None,\n",
    "    min_samples_split=5, random_state=42, n_jobs=-1\n",
    ")\n",
    "rf_clf.fit(X_train_c, y_train_c)\n",
    "y_pred_rf_c = rf_clf.predict(X_test_c)\n",
    "\n",
    "acc_rf_c = accuracy_score(y_test_c, y_pred_rf_c)\n",
    "f1_rf_c  = f1_score(y_test_c, y_pred_rf_c, average='weighted')\n",
    "\n",
    "print('=== Random Forest Classifier ===')\n",
    "print(f'Accuracy : {acc_rf_c:.4f}')\n",
    "print(f'F1-score : {f1_rf_c:.4f}')\n",
    "print()\n",
    "print('Rapport de classification :')\n",
    "print(classification_report(y_test_c, y_pred_rf_c, target_names=le_target.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000048b",
   "metadata": {},
   "source": [
    "> **Interprétation :** Le Random Forest Classifier améliore les performances sur la plupart des classes. Sa nature **ensembliste** et sa capacité à gérer naturellement des espaces de features mixtes (numériques + encodés) lui confèrent un avantage. Le F1-score pondéré plus élevé confirme qu'il gère mieux le déséquilibre des classes que le SVM. On note que même ce modèle peine sur les types très rares (`2fmCon`, `Twnhs`) — avec seulement une vingtaine d'exemples de test par classe, la moindre erreur impacte fortement les métriques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000049",
   "metadata": {},
   "source": [
    "### 5.4 Matrices de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000050",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "class_names = le_target.classes_\n",
    "\n",
    "for ax, (y_pred, title) in zip(axes, [\n",
    "    (y_pred_svm,  'SVM (RBF)'),\n",
    "    (y_pred_rf_c, 'Random Forest')\n",
    "]):\n",
    "    cm = confusion_matrix(y_test_c, y_pred)\n",
    "    sns.heatmap(\n",
    "        cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "        xticklabels=class_names, yticklabels=class_names, linewidths=0.5\n",
    "    )\n",
    "    ax.set_title(f'Matrice de confusion — {title}', fontsize=13, fontweight='bold')\n",
    "    ax.set_xlabel('Prédit')\n",
    "    ax.set_ylabel('Réel')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000050b",
   "metadata": {},
   "source": [
    "> **Interprétation :** La matrice de confusion permet d'identifier **quels types de bâtiments sont confondus** entre eux :\n",
    ">\n",
    "> - **Diagonale principale** (bleu foncé) : prédictions correctes. Les deux modèles classifient très bien `1Fam` (classe dominante).\n",
    "> - **Hors diagonale** : erreurs de classification. Les confusions les plus fréquentes concernent les classes minoritaires :\n",
    ">   - `TwnhsE` et `Twnhs` sont souvent confondus l'un avec l'autre — logique, car les maisons de ville intérieures et d'extrémité partagent des caractéristiques similaires (surface, nombre de pièces, quartier).\n",
    ">   - `Duplex` et `2fmCon` sont parfois classés en `1Fam` par les deux modèles.\n",
    ">\n",
    "> Le **Random Forest** fait moins d'erreurs hors diagonale que le SVM, confirmant sa supériorité sur ce problème de classification déséquilibré."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000051",
   "metadata": {},
   "source": [
    "### 5.5 Comparaison des modèles de Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000052",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_clf = pd.DataFrame({\n",
    "    'Modèle':              ['SVM (RBF)', 'Random Forest'],\n",
    "    'Accuracy':            [acc_svm, acc_rf_c],\n",
    "    'F1-score (weighted)': [f1_svm,  f1_rf_c]\n",
    "})\n",
    "print(results_clf.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000053",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "colors = ['seagreen', 'coral']\n",
    "\n",
    "for ax, metric in zip(axes, ['Accuracy', 'F1-score (weighted)']):\n",
    "    bars = ax.bar(results_clf['Modèle'], results_clf[metric], color=colors, edgecolor='white', width=0.4)\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.set_title(f'Comparaison — {metric}', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.axhline(1, color='gray', linestyle='--', linewidth=0.8, alpha=0.5)\n",
    "    for bar, val in zip(bars, results_clf[metric]):\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            bar.get_height() + 0.01,\n",
    "            f'{val:.4f}',\n",
    "            ha='center', va='bottom', fontsize=11, fontweight='bold'\n",
    "        )\n",
    "\n",
    "plt.suptitle('Comparaison des modèles de Classification', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000053b",
   "metadata": {},
   "source": [
    "> **Interprétation :** Le **Random Forest surpasse le SVM** sur les deux métriques. La différence est particulièrement notable sur le **F1-score pondéré**, qui reflète mieux les performances réelles sur un dataset déséquilibré. Le SVM, bien que théoriquement puissant pour les problèmes de classification non-linéaire, est plus sensible au déséquilibre des classes et nécessiterait des ajustements supplémentaires (paramètre `class_weight='balanced'`, sur-échantillonnage) pour rivaliser avec le Random Forest dans ce contexte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1000054",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_clf = pd.Series(rf_clf.feature_importances_, index=CLF_FEATURES).sort_values(ascending=True)\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "importances_clf.plot(kind='barh', color='seagreen', edgecolor='white')\n",
    "plt.title('Importance des features — Random Forest Classification', fontsize=13, fontweight='bold')\n",
    "plt.xlabel('Importance relative')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000054b",
   "metadata": {},
   "source": [
    "> **Interprétation :** Pour la classification du type de bâtiment :\n",
    ">\n",
    "> - **`Neighborhood`** est la feature la plus discriminante — certains quartiers sont exclusivement composés de maisons individuelles, d'autres de complexes résidentiels. La localisation est donc un signal fort du type de construction.\n",
    "> - **`HouseStyle`** (style architectural) contribue également de manière significative — une maison de style Tudor ou Ranch est généralement une maison individuelle, tandis que les styles contemporains peuvent correspondre à des maisons de ville.\n",
    "> - **`OverallQual`** et **`YearBuilt`** apportent des informations complémentaires : les constructions récentes sont plus souvent des maisons de ville dans des quartiers denses.\n",
    "> - **`TotRmsAbvGrd`** contribue le moins — le nombre de pièces est similaire entre certains types (une maison de ville peut avoir autant de pièces qu'une maison individuelle)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1000055",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Conclusion Générale\n",
    "\n",
    "### 6.1 Bilan de la Régression — Estimation de SalePrice\n",
    "\n",
    "Les deux modèles de régression ont été entraînés sur 15 features immobilières pour prédire le prix de vente d'un bien :\n",
    "\n",
    "| Modèle | MAE ($) | RMSE ($) | R² |\n",
    "|---|---|---|---|\n",
    "| Decision Tree (max_depth=10) | *(valeur après exécution)* | *(valeur après exécution)* | *(valeur après exécution)* |\n",
    "| **Random Forest (200 arbres)** | ***(valeur après exécution)*** | ***(valeur après exécution)*** | ***(valeur après exécution)*** |\n",
    "\n",
    "**Le Random Forest Regressor est nettement supérieur au Decision Tree** sur toutes les métriques. En agrégeant 200 arbres entraînés sur des sous-échantillons aléatoires, il réduit la variance et améliore la généralisation. La qualité globale du bien (`OverallQual`), la surface habitable (`GrLivArea`) et la superficie du garage (`GarageArea`) sont les trois variables les plus déterminantes du prix — ce qui est parfaitement cohérent avec la réalité du marché immobilier.\n",
    "\n",
    "Une limite observée : les deux modèles sous-estiment systématiquement les biens très chers (> 400 000 $), en raison de la rareté de ces observations dans le dataset d'entraînement.\n",
    "\n",
    "---\n",
    "\n",
    "### 6.2 Bilan de la Classification — Identification du Type de Bâtiment\n",
    "\n",
    "Les deux modèles de classification ont été entraînés sur 7 features pour prédire le type de bâtiment (`BldgType`) :\n",
    "\n",
    "| Modèle | Accuracy | F1-score (weighted) |\n",
    "|---|---|---|\n",
    "| SVM (RBF, C=10) | *(valeur après exécution)* | *(valeur après exécution)* |\n",
    "| **Random Forest (200 arbres)** | ***(valeur après exécution)*** | ***(valeur après exécution)*** |\n",
    "\n",
    "**Le Random Forest Classifier surpasse le SVM**, particulièrement sur les classes minoritaires. Le fort déséquilibre du dataset (84% de maisons individuelles `1Fam`) est le principal obstacle : l'accuracy seule est trompeuse, et le F1-score pondéré est la métrique la plus pertinente. Le quartier (`Neighborhood`) et le style architectural (`HouseStyle`) sont les features les plus discriminantes pour identifier le type de bâtiment.\n",
    "\n",
    "---\n",
    "\n",
    "### 6.3 Comparaison globale des algorithmes\n",
    "\n",
    "| Critère | Decision Tree | Random Forest | SVM |\n",
    "|---|---|---|---|\n",
    "| Précision | Moyenne | **Élevée** | Moyenne |\n",
    "| Interprétabilité | **Élevée** | Faible | Faible |\n",
    "| Robustesse aux outliers | Faible | **Bonne** | Moyenne |\n",
    "| Gestion du déséquilibre | Faible | **Bonne** | Faible |\n",
    "| Temps d'entraînement | **Rapide** | Modéré | Modéré |\n",
    "\n",
    "---\n",
    "\n",
    "### 6.4 Pistes d'amélioration\n",
    "\n",
    "1. **Rééchantillonnage** : appliquer SMOTE (*Synthetic Minority Oversampling Technique*) pour équilibrer les classes de BldgType et améliorer la classification des types rares.\n",
    "2. **Optimisation des hyperparamètres** : utiliser `GridSearchCV` ou `RandomizedSearchCV` pour affiner les paramètres des modèles (profondeur, nombre d'arbres, C du SVM).\n",
    "3. **Feature engineering** : créer de nouvelles variables (ex. ratio surface/nombre de pièces, âge du bien) pour enrichir l'information disponible.\n",
    "4. **Traitement des outliers** : identifier et traiter les observations aberrantes dans `SalePrice` et `LotArea` pour améliorer la robustesse de la régression.\n",
    "5. **Modèles avancés** : tester des algorithmes de boosting comme `XGBoost` ou `LightGBM`, qui surpassent généralement le Random Forest sur les données tabulaires structurées."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
